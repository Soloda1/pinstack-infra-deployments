services:
  ######################
  # Postgres (user-service)
  ######################
  user-db:
    image: postgres:16-alpine
    container_name: pinstack-user-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: userservice
      POSTGRES_PORT: 5432
    command: postgres -p 5432
    volumes:
      - user_postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5432"]
      interval: 5s
      timeout: 5s
      retries: 5

  user-migrator:
    container_name: pinstack-user-migrator
    build:
      context: ../pinstack-user-service
      dockerfile: Dockerfile.migrator
    depends_on:
      user-db:
        condition: service_healthy
    volumes:
      - ../pinstack-user-service/migrations:/app/migrations
      - ../pinstack-user-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    command: ./migrator -command up

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pinstack-user-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_LISTEN_PORT: 5050
    ports:
      - "5050:5050"
    depends_on:
      user-db:
        condition: service_healthy
    networks:
      - pinstack

  user-service:
    container_name: pinstack-user-service
    build:
      context: ../pinstack-user-service
      dockerfile: Dockerfile
    depends_on:
      user-migrator:
        condition: service_completed_successfully
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "50051:50051"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"

  ######################
  # Postgres (auth-service)
  ######################
  auth-db:
    image: postgres:16-alpine
    container_name: pinstack-auth-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: authservice
      POSTGRES_PORT: 5433
    command: postgres -p 5433
    volumes:
      - auth_postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5433"
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5433"]
      interval: 5s
      timeout: 5s
      retries: 5

  auth-migrator:
    container_name: pinstack-auth-migrator
    build:
      context: ../pinstack-auth-service
      dockerfile: Dockerfile.migrator
    depends_on:
      auth-db:
        condition: service_healthy
    volumes:
      - ../pinstack-auth-service/migrations:/app/migrations
      - ../pinstack-auth-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    command: ./migrator -command up

  auth-service:
    container_name: pinstack-auth-service
    build:
      context: ../pinstack-auth-service
      dockerfile: Dockerfile
    depends_on:
      auth-migrator:
        condition: service_completed_successfully
      user-service:
        condition: service_started
    volumes:
      - ../pinstack-auth-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "50052:50052"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"

  ######################
  # Postgres (post-service)
  ######################
  post-db:
    image: postgres:16-alpine
    container_name: pinstack-post-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: postservice
      POSTGRES_PORT: 5434
    command: postgres -p 5434
    volumes:
      - post_postgres_data:/var/lib/postgresql/data
    ports:
      - "5434:5434"
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5434"]
      interval: 5s
      timeout: 5s
      retries: 5

  post-migrator:
    container_name: pinstack-post-migrator
    build:
      context: ../pinstack-post-service
      dockerfile: Dockerfile.migrator
    depends_on:
      post-db:
        condition: service_healthy
    volumes:
      - ../pinstack-post-service/migrations:/app/migrations
      - ../pinstack-post-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    command: ./migrator -command up

  post-service:
    container_name: pinstack-post-service
    build:
      context: ../pinstack-post-service
      dockerfile: Dockerfile
    depends_on:
      post-migrator:
        condition: service_completed_successfully
      user-service:
        condition: service_started
    volumes:
      - ../pinstack-post-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "50053:50053"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"

  ######################
  # Postgres (relation-service)
  ######################
  relation-db:
    image: postgres:16-alpine
    container_name: pinstack-relation-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: relationservice
      POSTGRES_PORT: 5435
    command: postgres -p 5435
    volumes:
      - relation_postgres_data:/var/lib/postgresql/data
    ports:
      - "5435:5435"
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5435"]
      interval: 5s
      timeout: 5s
      retries: 5

  relation-migrator:
    container_name: pinstack-relation-migrator
    build:
      context: ../pinstack-relation-service
      dockerfile: Dockerfile.migrator
    depends_on:
      relation-db:
        condition: service_healthy
    volumes:
      - ../pinstack-relation-service/migrations:/app/migrations
      - ../pinstack-relation-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    command: ./migrator -command up

  relation-service:
    container_name: pinstack-relation-service
    build:
      context: ../pinstack-relation-service
      dockerfile: Dockerfile
    depends_on:
      relation-migrator:
        condition: service_completed_successfully
      user-service:
        condition: service_started
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    volumes:
      - ../pinstack-relation-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "50054:50054"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"

  ##################
  # API Gateway
  ##################
  api-gateway:
    container_name: pinstack-api-gateway
    build:
      context: ../pinstack-api-gateway
      dockerfile: Dockerfile
    depends_on:
      - user-service
      - auth-service
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "8080:8080"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"

  ##################
  # NGINX
  ##################
  nginx:
    image: nginx:alpine
    container_name: pinstack-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api-gateway
    networks:
      - pinstack

  ##################
  # Kafka (KRaft mode for notifications)
  ##################
  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: pinstack-kafka1
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka1:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG4J_ROOT_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_LOGGERS: "org.apache.kafka=ERROR,kafka=ERROR,kafka.cluster=ERROR,kafka.controller=ERROR,kafka.coordinator=ERROR,kafka.log=ERROR,kafka.server=ERROR,kafka.zookeeper=ERROR,kafka.network=ERROR,state.change.logger=ERROR"
      KAFKA_TOOLS_LOG4J_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_APPENDER_STDOUT_THRESHOLD: "ERROR"
      KAFKA_AUTHORIZER_LOGGER_NAME: "ERROR"
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote=false"
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_LOG_LEVEL: "ERROR"
    volumes:
      - kafka1_data:/var/lib/kafka/data
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka1:9092 --list > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
        tag: "kafka1-only-errors"
        env: "KAFKA_LOG4J_ROOT_LOGLEVEL=ERROR"

  kafka2:
    image: confluentinc/cp-kafka:latest
    container_name: pinstack-kafka2
    hostname: kafka2
    ports:
      - "9093:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka2:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG4J_ROOT_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_LOGGERS: "org.apache.kafka=ERROR,kafka=ERROR,kafka.cluster=ERROR,kafka.controller=ERROR,kafka.coordinator=ERROR,kafka.log=ERROR,kafka.server=ERROR,kafka.zookeeper=ERROR,kafka.network=ERROR,state.change.logger=ERROR"
      KAFKA_TOOLS_LOG4J_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_APPENDER_STDOUT_THRESHOLD: "ERROR"
      KAFKA_AUTHORIZER_LOGGER_NAME: "ERROR"
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote=false"
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_LOG_LEVEL: "ERROR"
    volumes:
      - kafka2_data:/var/lib/kafka/data
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka2:9092 --list > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
        tag: "kafka2-only-errors"
        env: "KAFKA_LOG4J_ROOT_LOGLEVEL=ERROR"

  kafka3:
    image: confluentinc/cp-kafka:latest
    container_name: pinstack-kafka3
    hostname: kafka3
    ports:
      - "9094:9092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:9093,2@kafka2:9093,3@kafka3:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,CONTROLLER://:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka3:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG4J_ROOT_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_LOGGERS: "org.apache.kafka=ERROR,kafka=ERROR,kafka.cluster=ERROR,kafka.controller=ERROR,kafka.coordinator=ERROR,kafka.log=ERROR,kafka.server=ERROR,kafka.zookeeper=ERROR,kafka.network=ERROR,state.change.logger=ERROR"
      KAFKA_TOOLS_LOG4J_LOGLEVEL: "ERROR"
      KAFKA_LOG4J_APPENDER_STDOUT_THRESHOLD: "ERROR"
      KAFKA_AUTHORIZER_LOGGER_NAME: "ERROR"
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote=false"
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      KAFKA_LOG_LEVEL: "ERROR"
    volumes:
      - kafka3_data:/var/lib/kafka/data
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka3:9092 --list > /dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
        tag: "kafka3-only-errors"
        env: "KAFKA_LOG4J_ROOT_LOGLEVEL=ERROR"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: pinstack-kafka-ui
    ports:
      - "9090:8080"
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: pinstack-local-kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9092,kafka3:9092
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - pinstack

  ######################
  # Postgres (notification-service)
  ######################
  notification-db:
    image: postgres:16-alpine
    container_name: pinstack-notification-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: notificationservice
      POSTGRES_PORT: 5436
    command: postgres -p 5436
    volumes:
      - notification_postgres_data:/var/lib/postgresql/data
    ports:
      - "5436:5436"
    networks:
      - pinstack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -p 5436"]
      interval: 5s
      timeout: 5s
      retries: 5

  notification-migrator:
    container_name: pinstack-notification-migrator
    build:
      context: ../pinstack-notification-service
      dockerfile: Dockerfile.migrator
    depends_on:
      notification-db:
        condition: service_healthy
    volumes:
      - ../pinstack-notification-service/migrations:/app/migrations
      - ../pinstack-notification-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    command: ./migrator -command up

  notification-service:
    container_name: pinstack-notification-service
    build:
      context: ../pinstack-notification-service
      dockerfile: Dockerfile
    depends_on:
      notification-migrator:
        condition: service_completed_successfully
      user-service:
        condition: service_started
      relation-service:
        condition: service_started
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    volumes:
      - ../pinstack-notification-service/config:/app/config
    environment:
      - ENV=dev
    networks:
      - pinstack
    ports:
      - "50055:50055"
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"



volumes:
  user_postgres_data:
  auth_postgres_data:
  post_postgres_data:
  relation_postgres_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  notification_postgres_data:

networks:
  pinstack:
    external: true
